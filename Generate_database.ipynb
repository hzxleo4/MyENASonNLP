{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"IMDB Dataset.csv\", header=0, quoting=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据清洗和预处理\n",
    "def review_to_words( raw_review ):\n",
    "    review_text = BeautifulSoup(raw_review).get_text()    \n",
    "    lettera_only1 = re.sub(\"\\.\",'. ',review_text)\n",
    "    letters_only = re.sub(\"[^a-zA-Z.]\", \" \", lettera_only1) \n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if w not in stops]   \n",
    "    return( \" \".join( meaningful_words ))\n",
    "num_reviews = train[\"review\"].size\n",
    "clean_reviews = []\n",
    "for i in range( 0, num_reviews ):\n",
    "    clean_reviews.append( review_to_words( train[\"review\"][i] ) )\n",
    "clean_train_reviews_wordlist = []\n",
    "num_train_reviews = 30000\n",
    "for i in range(0,num_train_reviews):\n",
    "    sentences = clean_reviews[i].split('. ')\n",
    "    #print(sentences)\n",
    "    sentences = [s.split() for s in sentences]\n",
    "    clean_train_reviews_wordlist += sentences\n",
    "    #print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=21969, vector_size=32, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(clean_train_reviews_wordlist,vector_size = 32, window=5, min_count=10, workers=4)\n",
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = w2v_model.wv.most_similar('happy', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_data(data,clean_views):\n",
    "    Y1 = data['sentiment']\n",
    "    s = len(Y1)\n",
    "    Y1[Y1 == 'positive'] = 1\n",
    "    Y1[Y1 == 'negative'] = 0\n",
    "    Y1 = Y1.values\n",
    "    Y = np.zeros([1,s])\n",
    "    Y = Y + Y1\n",
    "    Y = Y.astype(float)\n",
    "    X = np.zeros([s,32])\n",
    "    for i in range(s):\n",
    "        paragraph = re.sub(\"\\.\",' ',clean_views[i])\n",
    "        wordlist = paragraph.split()\n",
    "        cnt = 0\n",
    "        for word in wordlist:\n",
    "            try:\n",
    "                X[i] += w2v_model.wv[word]\n",
    "                cnt += 1\n",
    "            except:\n",
    "                continue\n",
    "        X[i] /= cnt\n",
    "    X = X.T\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = Make_data(train,clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 50000), (1, 50000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.T\n",
    "y = y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X.txt\", X, fmt=\"%d\", delimiter=\",\")\n",
    "np.savetxt(\"y.txt\", y, fmt=\"%d\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
